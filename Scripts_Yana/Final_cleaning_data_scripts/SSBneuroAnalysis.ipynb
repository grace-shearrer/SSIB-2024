{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c55a1b3b",
   "metadata": {},
   "source": [
    "https://data-dict.abcdstudy.org/?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4afd7d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import  scipy.signal.signaltools\n",
    "\n",
    "def _centered(arr, newsize):\n",
    "    # Return the center newsize portion of the array.\n",
    "    newsize = np.asarray(newsize)\n",
    "    currsize = np.array(arr.shape)\n",
    "    startind = (currsize - newsize) // 2\n",
    "    endind = startind + newsize\n",
    "    myslice = [slice(startind[k], endind[k]) for k in range(len(endind))]\n",
    "    return arr[tuple(myslice)]\n",
    "\n",
    "scipy.signal.signaltools._centered = _centered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62fb0ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gracer/opt/anaconda3/lib/python3.8/site-packages/statsmodels/tsa/base/tsa_model.py:7: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import (to_datetime, Int64Index, DatetimeIndex, Period,\n",
      "/Users/gracer/opt/anaconda3/lib/python3.8/site-packages/statsmodels/tsa/base/tsa_model.py:7: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import (to_datetime, Int64Index, DatetimeIndex, Period,\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9fa766a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gracer/opt/anaconda3/lib/python3.8/site-packages/nilearn/input_data/__init__.py:23: FutureWarning: The import path 'nilearn.input_data' is deprecated in version 0.9. Importing from 'nilearn.input_data' will be possible at least until release 0.13.0. Please import from 'nilearn.maskers' instead.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nilearn\n",
    "import numpy as np\n",
    "import glob \n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from scipy.stats import rankdata, ttest_rel, ttest_1samp\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.transforms as mtransforms\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import nibabel as nib\n",
    "from nilearn.input_data import NiftiLabelsMasker\n",
    "from nilearn.plotting import plot_glass_brain, plot_stat_map, view_img, view_img_on_surf\n",
    "\n",
    "from nltools.data import Brain_Data, Adjacency\n",
    "from nltools.mask import roi_to_brain, expand_mask\n",
    "from nltools.stats import fdr, threshold\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b57f201a",
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = '/Users/gracer/Library/CloudStorage/OneDrive-UniversityofWyoming/0. Lab/M2AENAD Lab - Documents/RESEARCH/ABCD/Yana_SSIB_2024/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21f653f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(basepath,'data','matched111724_centered_dum.csv'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "034c20ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3700\n"
     ]
    }
   ],
   "source": [
    "# Get number of subjects\n",
    "n = df.shape[0]\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85b2478a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonBrain = df[['demo_comb_income_v2','interview_age', 'bmi_perc',  'sex_M']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b7595f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demo_comb_income_v2</th>\n",
       "      <th>interview_age</th>\n",
       "      <th>bmi_perc</th>\n",
       "      <th>sex_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.134865</td>\n",
       "      <td>2.208108</td>\n",
       "      <td>-0.074089</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.134865</td>\n",
       "      <td>-3.791892</td>\n",
       "      <td>-0.166220</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-6.865135</td>\n",
       "      <td>2.208108</td>\n",
       "      <td>-0.117158</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.134865</td>\n",
       "      <td>-0.791892</td>\n",
       "      <td>0.181997</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.865135</td>\n",
       "      <td>-0.791892</td>\n",
       "      <td>0.132754</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3695</th>\n",
       "      <td>0.134865</td>\n",
       "      <td>6.208108</td>\n",
       "      <td>-0.089739</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3696</th>\n",
       "      <td>1.134865</td>\n",
       "      <td>11.208108</td>\n",
       "      <td>-0.092898</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3697</th>\n",
       "      <td>-0.865135</td>\n",
       "      <td>-4.791892</td>\n",
       "      <td>0.209150</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3698</th>\n",
       "      <td>2.134865</td>\n",
       "      <td>12.208108</td>\n",
       "      <td>0.009343</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3699</th>\n",
       "      <td>1.134865</td>\n",
       "      <td>5.208108</td>\n",
       "      <td>0.314276</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3700 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      demo_comb_income_v2  interview_age  bmi_perc  sex_M\n",
       "0                1.134865       2.208108 -0.074089      1\n",
       "1                1.134865      -3.791892 -0.166220      0\n",
       "2               -6.865135       2.208108 -0.117158      1\n",
       "3                0.134865      -0.791892  0.181997      0\n",
       "4               -3.865135      -0.791892  0.132754      0\n",
       "...                   ...            ...       ...    ...\n",
       "3695             0.134865       6.208108 -0.089739      1\n",
       "3696             1.134865      11.208108 -0.092898      0\n",
       "3697            -0.865135      -4.791892  0.209150      0\n",
       "3698             2.134865      12.208108  0.009343      1\n",
       "3699             1.134865       5.208108  0.314276      1\n",
       "\n",
       "[3700 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonBrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b726b950",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROIs = df.filter(like='rsfmri_', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ce881c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3700, 416)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROIs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ab3824bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ROIs.join(nonBrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb4fe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(ROIS2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdfc9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Set sex to 0 for M and 1 for female  \n",
    "df.replace({'sex': {'F': 1, 'M': 0}}, inplace=True)\n",
    "\n",
    "#4. Set ssb groups to low =0, medium = 1, and high = 2  \n",
    "df.replace({'ssb_group': {'low': 0, 'high': 2}}, inplace=True)\n",
    "\n",
    "#5. Drop the medium group  \n",
    "df = df[df['ssb_group'] != \"medium\"]\n",
    "\n",
    "#6. Create a dataframe called 'X' that is a subset of the dataframe with only the columns in the ROIS list.\n",
    "X = df[ROIS]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c07841",
   "metadata": {},
   "source": [
    "# checking what is different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1486df6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to sets and use symmetric difference\n",
    "result = list(set(ROIS) ^ set(ROIS2))\n",
    "print(result)  # Output: [1, 2, 3, 6, 7, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed6988b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ssb_group'] = df['ssb_group'].replace({'low':0,'high':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069147d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Set ssb groups to low =0, medium = 1, and high = 2  \n",
    "#df.replace({'ssb_group': {'low': 0, 'high': 2}}, inplace=True)\n",
    "#3. Set sex to 0 for M and 1 for female  \n",
    "df.replace({'sex': {'F': 1, 'M': 0}}, inplace=True)\n",
    "\n",
    "#5. Drop the medium group  \n",
    "df = df[df['ssb_group'] != \"medium\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb51e282",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[ROIS] #features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b62315",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150ab41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose the DataFrame to make columns become rows\n",
    "X_T = X.T\n",
    "\n",
    "duplicates = X_T.duplicated(keep='first')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b23f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying columns to drop (all duplicates except the first occurrence)\n",
    "cols_to_drop = X_T[duplicates].index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9b2e89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop the duplicate columns from the original DataFrame\n",
    "X_cleaned = X.drop(cols_to_drop, axis=1)\n",
    "\n",
    "print(X_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bb569f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ea9c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cleaned.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dacb6e6",
   "metadata": {},
   "source": [
    "# Factor of interest\n",
    "This is sometimes called the target. Right now I am using sex, but eventually we will change this to SSB group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92385f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['ssb_group'] #target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0308d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330cb5d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6dcd96a",
   "metadata": {},
   "source": [
    "# Train and test datasets\n",
    "Get randomly generated train and test datasets\n",
    "- Train 1 = train the model and feature elimination\n",
    "- Train 2 = cross validate the model\n",
    "- Test = test statistical differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ae8db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_cleaned, y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f427da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_train2, y_train1, y_train2 = train_test_split(X_train, y_train, random_state=42)\n",
    "X_test.shape\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8599c9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set(y_train1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb58d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Define the maximum value for ANOVA K parameter (10% of X_test sample)\n",
    "max_anova_k = int(len(X_test) * 0.1) #made it an integer, cause it's 92.7 and float can't be used in the script below\n",
    "\n",
    "# Make a list of ANOVA K parameters with intervals of 10\n",
    "ANOVAK = list(range(10, max_anova_k+1, 10)) #range 10-max_anova_k (+1 bcs otherwise the last number won't be included to the range), steps - 10\n",
    "\n",
    "#2. Make a list of svc__C parameters that include 0.1, 1, 10, 100\n",
    "#call this list 'svcC'\n",
    "svcC = [0.1, 1, 10, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc8d517",
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_filter = SelectKBest(f_classif)\n",
    "svm = SVC(kernel='linear')\n",
    "\n",
    "anova_svm = Pipeline([\n",
    "    ('anova', anova_filter),\n",
    "    ('svc', svm)\n",
    "])\n",
    "# Define a range of parameters for feature selection and SVM\n",
    "param_grid = {\n",
    "    'anova__k': [50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60],  # Trying different numbers of top features\n",
    "    'svc__C': [0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14, 0.15],  # SVM regularization parameter\n",
    "}\n",
    "\n",
    "# Setup GridSearchCV\n",
    "grid_search = GridSearchCV(anova_svm, param_grid=param_grid, cv=10, n_jobs=4)\n",
    "grid_search.fit(X_train1, y_train1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cc6244",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bestK = []\n",
    "bestC = []\n",
    "bestModel = []\n",
    "for i in range(49):\n",
    "    print(i)\n",
    "    #Setup GridSearchCV\n",
    "    grid_search = GridSearchCV(anova_svm, param_grid=param_grid, cv=10, n_jobs=4)\n",
    "    bestModel.append(grid_search)\n",
    "    grid_search.fit(X_train1, y_train1)\n",
    "    bestK.append(grid_search.best_params_['anova__k'])\n",
    "    bestC.append(grid_search.best_params_['svc__C'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd62aa0",
   "metadata": {},
   "source": [
    "## Initial\n",
    "* anova_initial = [10,20,30,40,50,60]\n",
    "* svc_C_initial = [0.1, 1, 10, 100]\n",
    "* Then narrowed to anova 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60\n",
    "* svc c 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14, 0.15\n",
    "## First try\n",
    "* Best parameters: {'anova__k': 51, 'svc__C': 0.15}\n",
    "* Best cross-validation score: 0.5530157342657344## Second try\n",
    "## 48 iterations \n",
    "* Best parameters: {'anova__k': 50, 'svc__C': 0.05}\n",
    "* Best cross-validation score: 0.7112026131762974\n",
    "# Note\n",
    "the model is much better with nonBrain regions. But still better than chance\n",
    "* Best parameters: {'anova__k': 52, 'svc__C': 0.12}\n",
    "* Best cross-validation score: 0.5713424733161576"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecd888d",
   "metadata": {},
   "source": [
    "## Check the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcce325e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bestK)\n",
    "print(bestC)\n",
    "# Find the best and then select the model from the bestModel list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57764cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0caecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming anova_svm is your original pipeline\n",
    "best_pipeline = Pipeline([\n",
    "    ('anova', SelectKBest(f_classif)),  # You don't need to specify k here; it will be set by best_params_\n",
    "    ('svc', SVC(kernel='linear'))      # No need to specify C here for the same reason\n",
    "])\n",
    "\n",
    "# Set the best parameters found for the entire pipeline\n",
    "best_pipeline.set_params(**grid_search.best_params_)\n",
    "\n",
    "# Now, retrain on the entire training set with the best parameters\n",
    "best_pipeline.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dcea12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "y_pred = best_pipeline.predict(X_train2)\n",
    "\n",
    "# Evaluate the model\n",
    "test_accuracy = accuracy_score(y_train2, y_pred)\n",
    "print(\"Test set accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373816e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_train2, y_pred, normalize = 'true')\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a621de",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(cm, annot=True,  cmap=\"Blues\")\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862a9cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the best set of parameters found by GridSearchCV\n",
    "best_parameters = grid_search.best_params_\n",
    "print(\"Best parameters found by GridSearchCV:\", best_parameters)\n",
    "\n",
    "# Access the best estimator directly\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"Best model:\", best_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc01caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the feature selection step ('anova' in your case)\n",
    "feature_selection_step = best_model.named_steps['anova']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f07c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mask of selected features (boolean array)\n",
    "selected_features_mask = feature_selection_step.get_support()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3515b805",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b69fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = X_train.columns[selected_features_mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7601e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e43c791",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0121e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce875cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_regression = X_test[selected_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b600eb",
   "metadata": {},
   "source": [
    "## Check high correlations between regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9776a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = X_regression.corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1fd501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the threshold for high correlation\n",
    "threshold = 0.8\n",
    "\n",
    "# Create a boolean mask for values above the threshold\n",
    "high_corr_mask = np.abs(correlation_matrix) > threshold\n",
    "\n",
    "# Mask the diagonal and lower triangle\n",
    "mask_upper_triangle = np.triu(np.ones(high_corr_mask.shape), k=1).astype(np.bool)\n",
    "\n",
    "# Combine masks\n",
    "final_mask = high_corr_mask & mask_upper_triangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa7b3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply mask to the correlation matrix\n",
    "high_corr_pairs = correlation_matrix.where(final_mask)\n",
    "\n",
    "# Stack the matrix and reset index to get pair-wise correlation in a readable format\n",
    "stacked_corr_pairs = high_corr_pairs.stack().reset_index()\n",
    "stacked_corr_pairs.columns = ['Feature 1', 'Feature 2', 'Correlation']\n",
    "\n",
    "print(stacked_corr_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c7b4f6",
   "metadata": {},
   "source": [
    "|#|feature 1|feature 2|r|\n",
    "|---|-------------------------------|--------------------------------|--------------|\n",
    "| 0  |    rsfmri_cor_ngd_au_scs_ptrh |  rsfmri_cor_ngd_rst_scs_crcxrh |    0.822824  |\n",
    "| 1 |  rsfmri_cor_ngd_cerc_scs_aglh |   rsfmri_cor_ngd_smh_scs_pllh  |     0.858514 |\n",
    "| 2 |    rsfmri_cor_ngd_cerc_scs_hprh|   rsfmri_cor_ngd_smh_scs_cderh|      0.867641|\n",
    "| 3 |    rsfmri_cor_ngd_cerc_scs_agrh|     rsfmri_cor_ngd_smh_scs_ptrh|      0.831211| \n",
    "|  4  | rsfmri_cor_ngd_cerc_scs_vtdcrh  |   rsfmri_cor_ngd_smh_scs_hprh  |    0.815776| \n",
    "| 5|   rsfmri_cor_ngd_copa_scs_thplh |    rsfmri_cor_ngd_smh_scs_aarh  |    0.877435| \n",
    "|  6  | rsfmri_cor_ngd_copa_scs_vtdclh  |   rsfmri_cor_ngd_smm_scs_hplh  |    0.864477| \n",
    "|  7 |  rsfmri_cor_ngd_copa_scs_crcxrh  |   rsfmri_cor_ngd_smm_scs_aglh   |   0.805186| "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9a80c9",
   "metadata": {},
   "source": [
    "|ABCD|Human|\n",
    "|---|----|\n",
    "|rsfmri_cor_ngd_au_scs_ptrh|\tAverage correlation between auditory network and ASEG ROI right-putamen|\n",
    "| rsfmri_cor_ngd_cerc_scs_aglh| Average correlation between cingulo-opercular network and ASEG ROI left-amygdala|\n",
    "|rsfmri_cor_ngd_cerc_scs_hprh|cingulo-opercular network and ASEG ROI right-hippocampus\t|\n",
    "|rsfmri_cor_ngd_cerc_scs_vtdcrh| cingulo-opercular network and ASEG ROI right-ventraldc|\n",
    "|rsfmri_cor_ngd_copa_scs_thplh|cingulo-parietal network and ASEG ROI left-thalamus-proper|\n",
    "|rsfmri_cor_ngd_copa_scs_crcxrh |cingulo-parietal network and ASEG ROI right-cerebellum-cortex|\n",
    "|sfmri_cor_ngd_rst_scs_crcxrh|retrosplenial temporal network and ASEG ROI right-cerebellum-cortex|\n",
    "|rsfmri_cor_ngd_smh_scs_pllh|Average correlation between sensorimotor hand network and ASEG ROI left-pallidum|\n",
    "|rsfmri_cor_ngd_smh_scs_cderh|Average correlation between sensorimotor hand network and ASEG ROI right-caudate|\n",
    "|rsfmri_cor_ngd_smh_scs_hprh|sensorimotor hand network and ASEG ROI right-hippocampus|\n",
    "|sfmri_cor_ngd_smh_scs_aarh\t|sensorimotor hand network and ASEG ROI right-accumbens-area|\n",
    "|rsfmri_cor_ngd_smm_scs_aglh|sensorimotor mouth network and ASEG ROI left-amygdala|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad93b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping cerebellar first\n",
    "columns_to_drop_list = ['rsfmri_cor_ngd_rst_scs_crcxrh','rsfmri_cor_ngd_copa_scs_crcxrh']\n",
    "\n",
    "X_regression_reduced = X_regression.drop(columns=columns_to_drop_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb744d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Assuming X_scaled is your scaled feature matrix and it's a numpy array\n",
    "#X_scaled_df = pd.DataFrame(X_scaled, columns=X_test_reg_sm.columns)  # Convert to DataFrame if necessary\n",
    "#X_scaled_df_with_const = sm.add_constant(X_scaled_df)  # Add constant for VIF calculation\n",
    "\n",
    "vifs = pd.Series([variance_inflation_factor(X_regression_reduced.values, i) \n",
    "                   for i in range(X_regression_reduced.shape[1])], \n",
    "                  index=X_regression_reduced.columns)\n",
    "\n",
    "print(vifs) # looks OK, everything is under 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf0da82",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_sm = sm.add_constant(X_regression_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd4cca9",
   "metadata": {},
   "source": [
    "# Create train, test datasets for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c1bcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainReg, X_testReg, y_trainReg, y_testReg = train_test_split(result_sm, y_test, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a37291",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_testReg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4843677e",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns =X_trainReg.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7de6d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4803d2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model on the training data\n",
    "model.fit(X_trainReg, y_trainReg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd50c2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "y_predReg = model.predict(X_testReg)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracyReg = accuracy_score(y_testReg, y_predReg)\n",
    "print(f\"Accuracy: {accuracyReg}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120c08f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficients\n",
    "coefficients = model.coef_\n",
    "# Intercepts\n",
    "intercepts = model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ccbbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_df = pd.DataFrame(coefficients, columns=selected_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0877553",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_df['Intercept'] = intercepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336b4c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['low']  # Adjust as per your classes\n",
    "coeff_df.index = class_names\n",
    "\n",
    "print(coeff_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a033dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(coeff_df.iloc[:, :-1], annot=False, cmap='coolwarm')  # Exclude intercepts for visualization\n",
    "plt.title('Coefficients of Multinomial Logistic Regression')\n",
    "plt.ylabel('Class')\n",
    "plt.xlabel('Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1d1f20",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fit the multinomial logistic regression model\n",
    "logit_model = sm.Logit(y_testReg, X_testReg)\n",
    "result = logit_model.fit()\n",
    "#model_sm = sm.MNLogit(y_testReg, X_test_reg_sm)\n",
    "#result_sm = model_sm.fit(method='newton', maxiter=5000)\n",
    "# Summary of the model\n",
    "# print(result_sm.summary())\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f50703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "predictions = result.predict(X_testReg)\n",
    "\n",
    "# Converting probabilities to class labels\n",
    "class_predictions = np.where(predictions > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84557121",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = y_testReg.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7063d30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPrevReal = pd.DataFrame({'real': array, 'pred': class_predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e74ce77",
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard = jaccard_score(dfPrevReal['real'], dfPrevReal['pred'])\n",
    "print(\"Jaccard Similarity Score:\", jaccard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0a57ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract p-values for all coefficients in the model\n",
    "p_values = result.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3669217",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b2a81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Benjamini-Hochberg FDR correction\n",
    "reject, pvals_corrected, _, _ = multipletests(p_values.values.flatten(), alpha=0.05, method='fdr_bh')\n",
    "\n",
    "# Reshape the corrected p-values to match the original shape\n",
    "pvals_corrected_reshaped = pvals_corrected.reshape(p_values.shape)\n",
    "\n",
    "# Create a DataFrame of the corrected p-values for easier interpretation\n",
    "# corrected_pvalues_df = pd.DataFrame(pvals_corrected_reshaped, index=p_values.index, columns=p_values.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd4946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvals_corrected_reshaped"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
